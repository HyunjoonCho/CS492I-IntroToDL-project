{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6e7ae9bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e7ae9bc",
        "outputId": "ec04df36-1b6e-4e16-f1bb-87d67c6ea072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.20.23-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 39.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.10.0+cu111)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.10.0.2)\n",
            "Collecting botocore<1.24.0,>=1.23.23\n",
            "  Downloading botocore-1.23.23-py3-none-any.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 52.4 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.23->boto3->pytorch-transformers) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.23->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.20.23 botocore-1.23.23 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 urllib3-1.25.11\n",
            "Cloning into 'CS492I-IntroToDL-project'...\n",
            "remote: Enumerating objects: 23169, done.\u001b[K\n",
            "remote: Counting objects: 100% (23169/23169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22680/22680), done.\u001b[K\n",
            "remote: Total 23169 (delta 451), reused 22952 (delta 258), pack-reused 0\n",
            "Receiving objects: 100% (23169/23169), 17.76 MiB | 18.52 MiB/s, done.\n",
            "Resolving deltas: 100% (451/451), done.\n",
            "Checking out files: 100% (22188/22188), done.\n"
          ]
        }
      ],
      "source": [
        "# !pip install pytorch-transformers\n",
        "# !git clone https://github.com/HyunjoonCho/CS492I-IntroToDL-project.git\n",
        "# import os\n",
        "# os.chdir('CS492I-IntroToDL-project')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9f5e34f4",
      "metadata": {
        "id": "9f5e34f4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "66beebd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66beebd0",
        "outputId": "a74292b0-8a3f-4a44-b4a7-53cd3b517693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "['BertForSequenceClassification_Category_best.ckpt', 'BertForSequenceClassification_Category_last.ckpt']\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')\n",
        "\n",
        "# drive_root = '/gdrive/My Drive/CS492I/project-pretrain'\n",
        "# print(os.listdir(Path(drive_root)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a465b83f",
      "metadata": {
        "id": "a465b83f"
      },
      "outputs": [],
      "source": [
        "from easydict import EasyDict as edict\n",
        "\n",
        "args = edict()\n",
        "args.gpu = True\n",
        "args.batch_size = 4\n",
        "args.num_epochs = 15\n",
        "args.learning_rate = 5e-5\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() and args.gpu else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "eeb76c36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeb76c36",
        "outputId": "e3371376-e3f7-456c-d004-a73384b6a536"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 995526/995526 [00:00<00:00, 5559179.56B/s]\n",
            "100%|██████████| 625/625 [00:00<00:00, 266758.93B/s]\n",
            "100%|██████████| 714314041/714314041 [00:20<00:00, 34590185.27B/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "bert_category_clf = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "da9d64f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da9d64f9",
        "outputId": "43e89bd1-ff56-459c-9bd3-bf0f138dfc98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1200 200 200\n"
          ]
        }
      ],
      "source": [
        "dataset_train = []\n",
        "dataset_val = []\n",
        "dataset_test = []\n",
        "\n",
        "root = Path('dataset/category')\n",
        "list = os.listdir(root)\n",
        "for cat in list:\n",
        "    files = os.listdir(root / cat)\n",
        "    for i,f in enumerate(files):\n",
        "        fname = root / cat / f\n",
        "        with open(fname, \"r\", encoding=\"utf-8\") as file:\n",
        "            strings = file.read()\n",
        "            if i < 150:\n",
        "                dataset_train.append([strings, cat])\n",
        "            elif i < 175:\n",
        "                dataset_val.append([strings, cat])\n",
        "            else:\n",
        "                dataset_test.append([strings,cat])\n",
        "\n",
        "print(len(dataset_train), len(dataset_val), len(dataset_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "52d14c2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52d14c2b",
        "outputId": "ecbe13a1-e21b-4743-9532-bcf0659a0af7",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[단독]조양호, 500억대 상속세 탈루 의혹…수사 착수\t조양호 한진그룹 회장 부부 소식입니다. \n",
            "\n",
            "조양호 회장이 수\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(dataset_train[0][0][:64]) #sentence\n",
        "print(dataset_train[0][1]) #label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3d09442e",
      "metadata": {
        "id": "3d09442e"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx):\n",
        "        # 현재 i[sent_idx] 가 본문\n",
        "        self.sentences = [i[sent_idx][:64] for i in dataset]\n",
        "        self.labels = [i[label_idx] for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.sentences[i], self.labels[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1ecd671b",
      "metadata": {
        "id": "1ecd671b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1)\n",
        "data_val = BERTDataset(dataset_val, 0, 1)\n",
        "data_test = BERTDataset(dataset_test, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b677a497",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b677a497",
        "outputId": "c6e05f6a-0473-4234-9379-681e8e2c616f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = DataLoader(data_train, batch_size=args.batch_size, num_workers=5, shuffle=True)\n",
        "val_dataloader = DataLoader(data_val, batch_size=args.batch_size, num_workers=5, shuffle=True)\n",
        "test_dataloader = DataLoader(data_test, batch_size=args.batch_size, num_workers=5, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cc73e400",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc73e400",
        "outputId": "2916ba96-8492-45bb-c206-e29278b4048b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_category_clf.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "510a6ea4",
      "metadata": {
        "id": "510a6ea4"
      },
      "outputs": [],
      "source": [
        "def save_model(model, mode='last'):\n",
        "    torch.save(model.state_dict(),  Path('pretrained_models') / f'{type(model).__name__}_Category_{mode}.ckpt')\n",
        "    # torch.save(model.state_dict(), Path(drive_root) / f'{type(model).__name__}_Category_{mode}.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d11f854c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d11f854c",
        "outputId": "b2fc2d3f-c24c-4c5b-d925-7054beb6c7c9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/15] -> Train Loss: 625.7171, Accuracy: 0.128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/15] -> Validation Loss: 103.4392, Accuracy: 0.125\n",
            "[Epoch 2/15] -> Train Loss: 610.3944, Accuracy: 0.174\n",
            "[Epoch 2/15] -> Validation Loss: 102.7240, Accuracy: 0.180\n",
            "[Epoch 3/15] -> Train Loss: 560.1364, Accuracy: 0.388\n",
            "[Epoch 3/15] -> Validation Loss: 84.9601, Accuracy: 0.535\n",
            "[Epoch 4/15] -> Train Loss: 483.4604, Accuracy: 0.551\n",
            "[Epoch 4/15] -> Validation Loss: 74.5309, Accuracy: 0.580\n",
            "[Epoch 5/15] -> Train Loss: 410.7262, Accuracy: 0.641\n",
            "[Epoch 5/15] -> Validation Loss: 65.1820, Accuracy: 0.645\n",
            "[Epoch 6/15] -> Train Loss: 356.0026, Accuracy: 0.703\n",
            "[Epoch 6/15] -> Validation Loss: 57.6310, Accuracy: 0.685\n",
            "[Epoch 7/15] -> Train Loss: 315.2721, Accuracy: 0.733\n",
            "[Epoch 7/15] -> Validation Loss: 54.2302, Accuracy: 0.685\n",
            "[Epoch 8/15] -> Train Loss: 281.6179, Accuracy: 0.767\n",
            "[Epoch 8/15] -> Validation Loss: 48.8490, Accuracy: 0.705\n",
            "[Epoch 9/15] -> Train Loss: 251.8812, Accuracy: 0.777\n",
            "[Epoch 9/15] -> Validation Loss: 44.9982, Accuracy: 0.725\n",
            "[Epoch 10/15] -> Train Loss: 228.4027, Accuracy: 0.805\n",
            "[Epoch 10/15] -> Validation Loss: 42.8418, Accuracy: 0.740\n",
            "[Epoch 11/15] -> Train Loss: 201.7863, Accuracy: 0.826\n",
            "[Epoch 11/15] -> Validation Loss: 40.6727, Accuracy: 0.750\n",
            "[Epoch 12/15] -> Train Loss: 181.6257, Accuracy: 0.838\n",
            "[Epoch 12/15] -> Validation Loss: 40.5905, Accuracy: 0.735\n",
            "[Epoch 13/15] -> Train Loss: 163.3839, Accuracy: 0.872\n",
            "[Epoch 13/15] -> Validation Loss: 38.9102, Accuracy: 0.760\n",
            "[Epoch 14/15] -> Train Loss: 149.2778, Accuracy: 0.874\n",
            "[Epoch 14/15] -> Validation Loss: 39.1575, Accuracy: 0.755\n",
            "[Epoch 15/15] -> Train Loss: 140.4718, Accuracy: 0.874\n",
            "[Epoch 15/15] -> Validation Loss: 38.1483, Accuracy: 0.760\n"
          ]
        }
      ],
      "source": [
        "#training step\n",
        "optimizer = optim.AdamW(bert_category_clf.parameters(), lr=1e-6)\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(args.num_epochs):\n",
        "    train_loss = 0\n",
        "    total_len = 0\n",
        "    total_correct = 0\n",
        "    bert_category_clf.train()\n",
        "    for sentence, label in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        encoded_list = [tokenizer.encode(t,add_special_tokens=True) for t in sentence]\n",
        "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "        \n",
        "        sample = torch.tensor(padded_list)\n",
        "        label = tuple((int(x[0])) for x in label)\n",
        "        label = torch.tensor(label)\n",
        "        sample = sample.to(device)\n",
        "        label = label.to(device)\n",
        "        \n",
        "        labels = torch.tensor(label)\n",
        "        loss, logits = bert_category_clf(sample, labels=labels)\n",
        "\n",
        "        pred = torch.argmax(F.softmax(logits), dim=1)        \n",
        "        correct = pred.eq(labels)\n",
        "        total_correct += correct.sum().item()\n",
        "        total_len += len(labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        #scheduler.step()        \n",
        "    print('[Epoch {}/{}] -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, args.num_epochs, train_loss, total_correct/total_len))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        bert_category_clf.eval()\n",
        "        val_loss = 0\n",
        "        v_total_correct = 0\n",
        "        v_total_len = 0\n",
        "        for sentence, label in val_dataloader:\n",
        "            encoded_list = [tokenizer.encode(t,add_special_tokens=True) for t in sentence]\n",
        "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "            \n",
        "            sample = torch.tensor(padded_list)\n",
        "            label = tuple((int(x[0])) for x in label)\n",
        "            label = torch.tensor(label)\n",
        "            sample = sample.to(device)\n",
        "            label = label.to(device)\n",
        "            \n",
        "            labels = torch.tensor(label)\n",
        "            loss, logits = bert_category_clf(sample, labels=labels)\n",
        "            \n",
        "            pred = torch.argmax(F.softmax(logits), dim=1)        \n",
        "            correct = pred.eq(labels)\n",
        "            val_loss += loss.item()\n",
        "            v_total_correct += correct.sum().item()\n",
        "            v_total_len += len(labels)\n",
        "        print('[Epoch {}/{}] -> Validation Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch + 1, args.num_epochs, val_loss, v_total_correct / v_total_len))\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        save_model(bert_category_clf, 'best')\n",
        "    save_model(bert_category_clf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "93eb1c59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93eb1c59",
        "outputId": "8f0b7b00-849d-476f-feb4-40d251281c5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy:  0.8\n"
          ]
        }
      ],
      "source": [
        "bert_category_clf.eval()\n",
        "\n",
        "t_total_len = 0\n",
        "t_total_correct = 0\n",
        "with torch.no_grad():\n",
        "    for sentence, label in test_dataloader:\n",
        "        encoded_list = [tokenizer.encode(t,add_special_tokens=True) for t in sentence]\n",
        "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "        sample = torch.tensor(padded_list)\n",
        "        label = tuple((int(x[0])) for x in label)\n",
        "        label = torch.tensor(label)\n",
        "        sample = sample.to(device)\n",
        "        label = label.to(device)\n",
        "            \n",
        "        labels = torch.tensor(label)\n",
        "        _, logits = bert_category_clf(sample, labels=labels)\n",
        "\n",
        "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "        correct = pred.eq(labels)\n",
        "        t_total_correct += correct.sum().item()\n",
        "        t_total_len += len(labels)\n",
        "\n",
        "print('Test accuracy: ', t_total_correct / t_total_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9e1ef3d0",
      "metadata": {
        "id": "9e1ef3d0"
      },
      "outputs": [],
      "source": [
        "def test_model(model, seq):\n",
        "    cate = [\"정치\",\"경제\",\"사회\", \"생활/문화\",\"세계\",\"기술/IT\", \"연예\", \"스포츠\"]\n",
        "    tmp = [seq]\n",
        "    encoded_list = [tokenizer.encode(t,add_special_tokens=True) for t in tmp]\n",
        "    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "    sample = torch.tensor(padded_list)\n",
        "\n",
        "    labels = torch.tensor([1]).unsqueeze(0)\n",
        "    sample = sample.to(device)\n",
        "    labels = labels.to(device)\n",
        "    _, logits = model(sample, labels=labels)\n",
        "\n",
        "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "\n",
        "    print(\"뉴스의 카테고리는:\", cate[pred])\n",
        "    print(\"신뢰도는:\", \"{:.2f}%\".format(F.softmax(logits).max().item() * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ad49b909",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad49b909",
        "outputId": "c0d13be2-ba9c-4c69-ad23-c311638ce774",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "뉴스의 카테고리는: 기술/IT\n",
            "신뢰도는: 86.46%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ],
      "source": [
        "test_model(bert_category_clf, \"SK텔레콤 분사 의결... '2025년 순자산 75조, 연 매출 22조 목표'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "category_clf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
