{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "\n",
    "args = edict()\n",
    "args.gpu = True\n",
    "args.input_dim = 1\n",
    "args.hidden_dim = 32\n",
    "args.num_layers = 2\n",
    "args.output_dim = 4\n",
    "args.num_epochs = 100\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() and args.gpu else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = '삼성전자'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kospi = fdr.StockListing('KOSPI')\n",
    "ticker = str(df_kospi.loc[df_kospi['Name'] == company_name]['Symbol'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-11-08</th>\n",
       "      <td>761</td>\n",
       "      <td>809</td>\n",
       "      <td>761</td>\n",
       "      <td>810</td>\n",
       "      <td>320624</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-10</th>\n",
       "      <td>809</td>\n",
       "      <td>872</td>\n",
       "      <td>809</td>\n",
       "      <td>870</td>\n",
       "      <td>376400</td>\n",
       "      <td>0.074074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-11</th>\n",
       "      <td>857</td>\n",
       "      <td>888</td>\n",
       "      <td>823</td>\n",
       "      <td>836</td>\n",
       "      <td>314560</td>\n",
       "      <td>-0.039080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-12</th>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>791</td>\n",
       "      <td>804</td>\n",
       "      <td>304710</td>\n",
       "      <td>-0.038278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-13</th>\n",
       "      <td>822</td>\n",
       "      <td>836</td>\n",
       "      <td>798</td>\n",
       "      <td>799</td>\n",
       "      <td>273800</td>\n",
       "      <td>-0.006219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06</th>\n",
       "      <td>75100</td>\n",
       "      <td>76700</td>\n",
       "      <td>74900</td>\n",
       "      <td>76300</td>\n",
       "      <td>16391250</td>\n",
       "      <td>0.009259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-07</th>\n",
       "      <td>76100</td>\n",
       "      <td>77700</td>\n",
       "      <td>75600</td>\n",
       "      <td>77400</td>\n",
       "      <td>19232453</td>\n",
       "      <td>0.014417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-08</th>\n",
       "      <td>78300</td>\n",
       "      <td>78600</td>\n",
       "      <td>77100</td>\n",
       "      <td>77400</td>\n",
       "      <td>21558340</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09</th>\n",
       "      <td>77400</td>\n",
       "      <td>78200</td>\n",
       "      <td>77000</td>\n",
       "      <td>78200</td>\n",
       "      <td>21604528</td>\n",
       "      <td>0.010336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-10</th>\n",
       "      <td>77400</td>\n",
       "      <td>77600</td>\n",
       "      <td>76800</td>\n",
       "      <td>76900</td>\n",
       "      <td>9091202</td>\n",
       "      <td>-0.016624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close    Volume    Change\n",
       "Date                                                      \n",
       "1997-11-08    761    809    761    810    320624       NaN\n",
       "1997-11-10    809    872    809    870    376400  0.074074\n",
       "1997-11-11    857    888    823    836    314560 -0.039080\n",
       "1997-11-12    831    831    791    804    304710 -0.038278\n",
       "1997-11-13    822    836    798    799    273800 -0.006219\n",
       "...           ...    ...    ...    ...       ...       ...\n",
       "2021-12-06  75100  76700  74900  76300  16391250  0.009259\n",
       "2021-12-07  76100  77700  75600  77400  19232453  0.014417\n",
       "2021-12-08  78300  78600  77100  77400  21558340  0.000000\n",
       "2021-12-09  77400  78200  77000  78200  21604528  0.010336\n",
       "2021-12-10  77400  77600  76800  76900   9091202 -0.016624\n",
       "\n",
       "[6000 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycompany = fdr.DataReader(ticker)\n",
    "mycompany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyFluctuation(fluctuation):\n",
    "    if fluctuation < -2.5:\n",
    "        return 0\n",
    "    elif fluctuation < 0:\n",
    "        return 1\n",
    "    elif fluctuation < 2.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-b510650c1e7b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price['Fluctuation'] = price['Close'].div(price['Close'].shift(1)).apply(lambda x : classifyFluctuation((x - 1) * 100))\n",
      "<ipython-input-8-b510650c1e7b>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price['Close'] = scaler.fit_transform(price['Close'].values.reshape(-1,1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Fluctuation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-11-08</th>\n",
       "      <td>-0.995950</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-10</th>\n",
       "      <td>-0.994622</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-11</th>\n",
       "      <td>-0.995375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-12</th>\n",
       "      <td>-0.996083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-13</th>\n",
       "      <td>-0.996194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06</th>\n",
       "      <td>0.674682</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-07</th>\n",
       "      <td>0.699025</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-08</th>\n",
       "      <td>0.699025</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09</th>\n",
       "      <td>0.716730</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-10</th>\n",
       "      <td>0.687960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close  Fluctuation\n",
       "Date                             \n",
       "1997-11-08 -0.995950            3\n",
       "1997-11-10 -0.994622            3\n",
       "1997-11-11 -0.995375            0\n",
       "1997-11-12 -0.996083            0\n",
       "1997-11-13 -0.996194            1\n",
       "...              ...          ...\n",
       "2021-12-06  0.674682            2\n",
       "2021-12-07  0.699025            2\n",
       "2021-12-08  0.699025            2\n",
       "2021-12-09  0.716730            2\n",
       "2021-12-10  0.687960            1\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = mycompany[['Close']]\n",
    "price['Fluctuation'] = price['Close'].div(price['Close'].shift(1)).apply(lambda x : classifyFluctuation((x - 1) * 100))\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "price['Close'] = scaler.fit_transform(price['Close'].values.reshape(-1,1))\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape =  (4484, 19, 1)\n",
      "y_train.shape =  (4484,)\n",
      "x_val.shape =  (748, 19, 1)\n",
      "y_val.shape =  (748,)\n",
      "x_test.shape =  (748, 19, 1)\n",
      "y_test.shape =  (748,)\n"
     ]
    }
   ],
   "source": [
    "def split_data(stock, lookback):\n",
    "    data_raw = stock.to_numpy() # convert to numpy array\n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - lookback): \n",
    "        data.append(data_raw[index: index + lookback])\n",
    "    \n",
    "    data = np.array(data)\n",
    "    val_and_test_set_size = int(np.round(0.125 * data.shape[0]))\n",
    "    train_set_size = data.shape[0] - 2 * (val_and_test_set_size)\n",
    "   \n",
    "    x_train = data[:train_set_size,:-1,:1]\n",
    "    y_train = data[:train_set_size,-1,1:].squeeze()\n",
    "\n",
    "    x_val = data[train_set_size:train_set_size + val_and_test_set_size,:-1,:1]\n",
    "    y_val = data[train_set_size:train_set_size + val_and_test_set_size,-1,1:].squeeze()\n",
    "    \n",
    "    x_test = data[train_set_size + val_and_test_set_size:,:-1,:1]\n",
    "    y_test = data[train_set_size + val_and_test_set_size:,-1,1:].squeeze()\n",
    "    \n",
    "    return [x_train, y_train, x_val, y_val, x_test, y_test]\n",
    "\n",
    "lookback = 20 # choose sequence length\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = split_data(price, lookback)\n",
    "print('x_train.shape = ',x_train.shape)\n",
    "print('y_train.shape = ',y_train.shape)\n",
    "print('x_val.shape = ',x_val.shape)\n",
    "print('y_val.shape = ',y_val.shape)\n",
    "print('x_test.shape = ',x_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "x_val = torch.from_numpy(x_val).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor).type(torch.LongTensor)\n",
    "y_val_lstm = torch.from_numpy(y_val).type(torch.Tensor).type(torch.LongTensor)\n",
    "y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_dim=args.input_dim, hidden_dim=args.hidden_dim, output_dim=args.output_dim, num_layers=args.num_layers)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/100] -> Train Loss: 1.3230, Accuracy: 0.379\n",
      "[Epoch 1/100] -> Validation Loss: 1.2202, Accuracy: 0.496\n",
      "[Epoch 2/100] -> Train Loss: 1.2985, Accuracy: 0.379\n",
      "[Epoch 2/100] -> Validation Loss: 1.1521, Accuracy: 0.496\n",
      "[Epoch 3/100] -> Train Loss: 1.2778, Accuracy: 0.379\n",
      "[Epoch 3/100] -> Validation Loss: 1.0888, Accuracy: 0.436\n",
      "[Epoch 4/100] -> Train Loss: 1.2942, Accuracy: 0.355\n",
      "[Epoch 4/100] -> Validation Loss: 1.1008, Accuracy: 0.496\n",
      "[Epoch 5/100] -> Train Loss: 1.2784, Accuracy: 0.379\n",
      "[Epoch 5/100] -> Validation Loss: 1.1271, Accuracy: 0.496\n",
      "[Epoch 6/100] -> Train Loss: 1.2713, Accuracy: 0.379\n",
      "[Epoch 6/100] -> Validation Loss: 1.1494, Accuracy: 0.496\n",
      "[Epoch 7/100] -> Train Loss: 1.2739, Accuracy: 0.379\n",
      "[Epoch 7/100] -> Validation Loss: 1.1578, Accuracy: 0.496\n",
      "[Epoch 8/100] -> Train Loss: 1.2761, Accuracy: 0.379\n",
      "[Epoch 8/100] -> Validation Loss: 1.1544, Accuracy: 0.496\n",
      "[Epoch 9/100] -> Train Loss: 1.2753, Accuracy: 0.379\n",
      "[Epoch 9/100] -> Validation Loss: 1.1440, Accuracy: 0.496\n",
      "[Epoch 10/100] -> Train Loss: 1.2729, Accuracy: 0.379\n",
      "[Epoch 10/100] -> Validation Loss: 1.1306, Accuracy: 0.496\n",
      "[Epoch 11/100] -> Train Loss: 1.2703, Accuracy: 0.379\n",
      "[Epoch 11/100] -> Validation Loss: 1.1173, Accuracy: 0.496\n",
      "[Epoch 12/100] -> Train Loss: 1.2687, Accuracy: 0.379\n",
      "[Epoch 12/100] -> Validation Loss: 1.1064, Accuracy: 0.496\n",
      "[Epoch 13/100] -> Train Loss: 1.2682, Accuracy: 0.379\n",
      "[Epoch 13/100] -> Validation Loss: 1.0992, Accuracy: 0.496\n",
      "[Epoch 14/100] -> Train Loss: 1.2682, Accuracy: 0.379\n",
      "[Epoch 14/100] -> Validation Loss: 1.0960, Accuracy: 0.496\n",
      "[Epoch 15/100] -> Train Loss: 1.2676, Accuracy: 0.379\n",
      "[Epoch 15/100] -> Validation Loss: 1.0962, Accuracy: 0.496\n",
      "[Epoch 16/100] -> Train Loss: 1.2655, Accuracy: 0.379\n",
      "[Epoch 16/100] -> Validation Loss: 1.0985, Accuracy: 0.410\n",
      "[Epoch 17/100] -> Train Loss: 1.2625, Accuracy: 0.380\n",
      "[Epoch 17/100] -> Validation Loss: 1.1010, Accuracy: 0.381\n",
      "[Epoch 18/100] -> Train Loss: 1.2597, Accuracy: 0.370\n",
      "[Epoch 18/100] -> Validation Loss: 1.0991, Accuracy: 0.418\n",
      "[Epoch 19/100] -> Train Loss: 1.2583, Accuracy: 0.380\n",
      "[Epoch 19/100] -> Validation Loss: 1.0878, Accuracy: 0.460\n",
      "[Epoch 20/100] -> Train Loss: 1.2534, Accuracy: 0.379\n",
      "[Epoch 20/100] -> Validation Loss: 1.0729, Accuracy: 0.496\n",
      "[Epoch 21/100] -> Train Loss: 1.2415, Accuracy: 0.379\n",
      "[Epoch 21/100] -> Validation Loss: 1.0642, Accuracy: 0.496\n",
      "[Epoch 22/100] -> Train Loss: 1.2390, Accuracy: 0.379\n",
      "[Epoch 22/100] -> Validation Loss: 1.0627, Accuracy: 0.496\n",
      "[Epoch 23/100] -> Train Loss: 1.2246, Accuracy: 0.379\n",
      "[Epoch 23/100] -> Validation Loss: 1.0636, Accuracy: 0.496\n",
      "[Epoch 24/100] -> Train Loss: 1.2352, Accuracy: 0.385\n",
      "[Epoch 24/100] -> Validation Loss: 1.0668, Accuracy: 0.496\n",
      "[Epoch 25/100] -> Train Loss: 1.2438, Accuracy: 0.379\n",
      "[Epoch 25/100] -> Validation Loss: 1.0666, Accuracy: 0.496\n",
      "[Epoch 26/100] -> Train Loss: 1.2241, Accuracy: 0.385\n",
      "[Epoch 26/100] -> Validation Loss: 1.0664, Accuracy: 0.496\n",
      "[Epoch 27/100] -> Train Loss: 1.2351, Accuracy: 0.379\n",
      "[Epoch 27/100] -> Validation Loss: 1.0674, Accuracy: 0.491\n",
      "[Epoch 28/100] -> Train Loss: 1.2225, Accuracy: 0.388\n",
      "[Epoch 28/100] -> Validation Loss: 1.0686, Accuracy: 0.381\n",
      "[Epoch 29/100] -> Train Loss: 1.2268, Accuracy: 0.378\n",
      "[Epoch 29/100] -> Validation Loss: 1.0695, Accuracy: 0.381\n",
      "[Epoch 30/100] -> Train Loss: 1.2273, Accuracy: 0.372\n",
      "[Epoch 30/100] -> Validation Loss: 1.0702, Accuracy: 0.381\n",
      "[Epoch 31/100] -> Train Loss: 1.2222, Accuracy: 0.377\n",
      "[Epoch 31/100] -> Validation Loss: 1.0707, Accuracy: 0.394\n",
      "[Epoch 32/100] -> Train Loss: 1.2265, Accuracy: 0.377\n",
      "[Epoch 32/100] -> Validation Loss: 1.0705, Accuracy: 0.467\n",
      "[Epoch 33/100] -> Train Loss: 1.2269, Accuracy: 0.385\n",
      "[Epoch 33/100] -> Validation Loss: 1.0693, Accuracy: 0.496\n",
      "[Epoch 34/100] -> Train Loss: 1.2229, Accuracy: 0.382\n",
      "[Epoch 34/100] -> Validation Loss: 1.0678, Accuracy: 0.496\n",
      "[Epoch 35/100] -> Train Loss: 1.2245, Accuracy: 0.382\n",
      "[Epoch 35/100] -> Validation Loss: 1.0665, Accuracy: 0.496\n",
      "[Epoch 36/100] -> Train Loss: 1.2250, Accuracy: 0.382\n",
      "[Epoch 36/100] -> Validation Loss: 1.0656, Accuracy: 0.496\n",
      "[Epoch 37/100] -> Train Loss: 1.2211, Accuracy: 0.384\n",
      "[Epoch 37/100] -> Validation Loss: 1.0650, Accuracy: 0.496\n",
      "[Epoch 38/100] -> Train Loss: 1.2224, Accuracy: 0.384\n",
      "[Epoch 38/100] -> Validation Loss: 1.0648, Accuracy: 0.496\n",
      "[Epoch 39/100] -> Train Loss: 1.2226, Accuracy: 0.384\n",
      "[Epoch 39/100] -> Validation Loss: 1.0652, Accuracy: 0.496\n",
      "[Epoch 40/100] -> Train Loss: 1.2202, Accuracy: 0.386\n",
      "[Epoch 40/100] -> Validation Loss: 1.0661, Accuracy: 0.496\n",
      "[Epoch 41/100] -> Train Loss: 1.2229, Accuracy: 0.385\n",
      "[Epoch 41/100] -> Validation Loss: 1.0671, Accuracy: 0.422\n",
      "[Epoch 42/100] -> Train Loss: 1.2208, Accuracy: 0.387\n",
      "[Epoch 42/100] -> Validation Loss: 1.0679, Accuracy: 0.381\n",
      "[Epoch 43/100] -> Train Loss: 1.2214, Accuracy: 0.378\n",
      "[Epoch 43/100] -> Validation Loss: 1.0687, Accuracy: 0.381\n",
      "[Epoch 44/100] -> Train Loss: 1.2219, Accuracy: 0.378\n",
      "[Epoch 44/100] -> Validation Loss: 1.0692, Accuracy: 0.381\n",
      "[Epoch 45/100] -> Train Loss: 1.2201, Accuracy: 0.382\n",
      "[Epoch 45/100] -> Validation Loss: 1.0692, Accuracy: 0.381\n",
      "[Epoch 46/100] -> Train Loss: 1.2214, Accuracy: 0.378\n",
      "[Epoch 46/100] -> Validation Loss: 1.0687, Accuracy: 0.381\n",
      "[Epoch 47/100] -> Train Loss: 1.2203, Accuracy: 0.377\n",
      "[Epoch 47/100] -> Validation Loss: 1.0680, Accuracy: 0.398\n",
      "[Epoch 48/100] -> Train Loss: 1.2202, Accuracy: 0.384\n",
      "[Epoch 48/100] -> Validation Loss: 1.0675, Accuracy: 0.447\n",
      "[Epoch 49/100] -> Train Loss: 1.2210, Accuracy: 0.387\n",
      "[Epoch 49/100] -> Validation Loss: 1.0671, Accuracy: 0.484\n",
      "[Epoch 50/100] -> Train Loss: 1.2200, Accuracy: 0.386\n",
      "[Epoch 50/100] -> Validation Loss: 1.0669, Accuracy: 0.496\n",
      "[Epoch 51/100] -> Train Loss: 1.2204, Accuracy: 0.383\n",
      "[Epoch 51/100] -> Validation Loss: 1.0669, Accuracy: 0.496\n",
      "[Epoch 52/100] -> Train Loss: 1.2206, Accuracy: 0.383\n",
      "[Epoch 52/100] -> Validation Loss: 1.0670, Accuracy: 0.496\n",
      "[Epoch 53/100] -> Train Loss: 1.2198, Accuracy: 0.385\n",
      "[Epoch 53/100] -> Validation Loss: 1.0673, Accuracy: 0.483\n",
      "[Epoch 54/100] -> Train Loss: 1.2203, Accuracy: 0.385\n",
      "[Epoch 54/100] -> Validation Loss: 1.0677, Accuracy: 0.447\n",
      "[Epoch 55/100] -> Train Loss: 1.2200, Accuracy: 0.385\n",
      "[Epoch 55/100] -> Validation Loss: 1.0682, Accuracy: 0.397\n",
      "[Epoch 56/100] -> Train Loss: 1.2197, Accuracy: 0.384\n",
      "[Epoch 56/100] -> Validation Loss: 1.0687, Accuracy: 0.381\n",
      "[Epoch 57/100] -> Train Loss: 1.2201, Accuracy: 0.381\n",
      "[Epoch 57/100] -> Validation Loss: 1.0689, Accuracy: 0.381\n",
      "[Epoch 58/100] -> Train Loss: 1.2195, Accuracy: 0.379\n",
      "[Epoch 58/100] -> Validation Loss: 1.0689, Accuracy: 0.381\n",
      "[Epoch 59/100] -> Train Loss: 1.2199, Accuracy: 0.377\n",
      "[Epoch 59/100] -> Validation Loss: 1.0687, Accuracy: 0.381\n",
      "[Epoch 60/100] -> Train Loss: 1.2197, Accuracy: 0.378\n",
      "[Epoch 60/100] -> Validation Loss: 1.0685, Accuracy: 0.381\n",
      "[Epoch 61/100] -> Train Loss: 1.2196, Accuracy: 0.380\n",
      "[Epoch 61/100] -> Validation Loss: 1.0681, Accuracy: 0.412\n",
      "[Epoch 62/100] -> Train Loss: 1.2198, Accuracy: 0.386\n",
      "[Epoch 62/100] -> Validation Loss: 1.0677, Accuracy: 0.445\n",
      "[Epoch 63/100] -> Train Loss: 1.2195, Accuracy: 0.386\n",
      "[Epoch 63/100] -> Validation Loss: 1.0674, Accuracy: 0.481\n",
      "[Epoch 64/100] -> Train Loss: 1.2197, Accuracy: 0.385\n",
      "[Epoch 64/100] -> Validation Loss: 1.0673, Accuracy: 0.495\n",
      "[Epoch 65/100] -> Train Loss: 1.2195, Accuracy: 0.386\n",
      "[Epoch 65/100] -> Validation Loss: 1.0674, Accuracy: 0.495\n",
      "[Epoch 66/100] -> Train Loss: 1.2196, Accuracy: 0.388\n",
      "[Epoch 66/100] -> Validation Loss: 1.0676, Accuracy: 0.468\n",
      "[Epoch 67/100] -> Train Loss: 1.2195, Accuracy: 0.387\n",
      "[Epoch 67/100] -> Validation Loss: 1.0678, Accuracy: 0.456\n",
      "[Epoch 68/100] -> Train Loss: 1.2194, Accuracy: 0.386\n",
      "[Epoch 68/100] -> Validation Loss: 1.0681, Accuracy: 0.422\n",
      "[Epoch 69/100] -> Train Loss: 1.2195, Accuracy: 0.385\n",
      "[Epoch 69/100] -> Validation Loss: 1.0683, Accuracy: 0.414\n",
      "[Epoch 70/100] -> Train Loss: 1.2194, Accuracy: 0.384\n",
      "[Epoch 70/100] -> Validation Loss: 1.0684, Accuracy: 0.389\n",
      "[Epoch 71/100] -> Train Loss: 1.2195, Accuracy: 0.380\n",
      "[Epoch 71/100] -> Validation Loss: 1.0684, Accuracy: 0.389\n",
      "[Epoch 72/100] -> Train Loss: 1.2194, Accuracy: 0.378\n",
      "[Epoch 72/100] -> Validation Loss: 1.0682, Accuracy: 0.394\n",
      "[Epoch 73/100] -> Train Loss: 1.2194, Accuracy: 0.379\n",
      "[Epoch 73/100] -> Validation Loss: 1.0679, Accuracy: 0.413\n",
      "[Epoch 74/100] -> Train Loss: 1.2194, Accuracy: 0.384\n",
      "[Epoch 74/100] -> Validation Loss: 1.0676, Accuracy: 0.422\n",
      "[Epoch 75/100] -> Train Loss: 1.2193, Accuracy: 0.386\n",
      "[Epoch 75/100] -> Validation Loss: 1.0674, Accuracy: 0.460\n",
      "[Epoch 76/100] -> Train Loss: 1.2193, Accuracy: 0.388\n",
      "[Epoch 76/100] -> Validation Loss: 1.0671, Accuracy: 0.496\n",
      "[Epoch 77/100] -> Train Loss: 1.2193, Accuracy: 0.386\n",
      "[Epoch 77/100] -> Validation Loss: 1.0670, Accuracy: 0.496\n",
      "[Epoch 78/100] -> Train Loss: 1.2193, Accuracy: 0.385\n",
      "[Epoch 78/100] -> Validation Loss: 1.0669, Accuracy: 0.496\n",
      "[Epoch 79/100] -> Train Loss: 1.2192, Accuracy: 0.386\n",
      "[Epoch 79/100] -> Validation Loss: 1.0670, Accuracy: 0.496\n",
      "[Epoch 80/100] -> Train Loss: 1.2193, Accuracy: 0.388\n",
      "[Epoch 80/100] -> Validation Loss: 1.0671, Accuracy: 0.496\n",
      "[Epoch 81/100] -> Train Loss: 1.2192, Accuracy: 0.387\n",
      "[Epoch 81/100] -> Validation Loss: 1.0672, Accuracy: 0.496\n",
      "[Epoch 82/100] -> Train Loss: 1.2192, Accuracy: 0.385\n",
      "[Epoch 82/100] -> Validation Loss: 1.0673, Accuracy: 0.496\n",
      "[Epoch 83/100] -> Train Loss: 1.2192, Accuracy: 0.385\n",
      "[Epoch 83/100] -> Validation Loss: 1.0674, Accuracy: 0.496\n",
      "[Epoch 84/100] -> Train Loss: 1.2192, Accuracy: 0.386\n",
      "[Epoch 84/100] -> Validation Loss: 1.0673, Accuracy: 0.496\n",
      "[Epoch 85/100] -> Train Loss: 1.2192, Accuracy: 0.386\n",
      "[Epoch 85/100] -> Validation Loss: 1.0672, Accuracy: 0.496\n",
      "[Epoch 86/100] -> Train Loss: 1.2192, Accuracy: 0.386\n",
      "[Epoch 86/100] -> Validation Loss: 1.0671, Accuracy: 0.496\n",
      "[Epoch 87/100] -> Train Loss: 1.2192, Accuracy: 0.385\n",
      "[Epoch 87/100] -> Validation Loss: 1.0669, Accuracy: 0.496\n",
      "[Epoch 88/100] -> Train Loss: 1.2191, Accuracy: 0.385\n",
      "[Epoch 88/100] -> Validation Loss: 1.0668, Accuracy: 0.496\n",
      "[Epoch 89/100] -> Train Loss: 1.2191, Accuracy: 0.386\n",
      "[Epoch 89/100] -> Validation Loss: 1.0666, Accuracy: 0.496\n",
      "[Epoch 90/100] -> Train Loss: 1.2191, Accuracy: 0.385\n",
      "[Epoch 90/100] -> Validation Loss: 1.0666, Accuracy: 0.496\n",
      "[Epoch 91/100] -> Train Loss: 1.2191, Accuracy: 0.384\n",
      "[Epoch 91/100] -> Validation Loss: 1.0666, Accuracy: 0.496\n",
      "[Epoch 92/100] -> Train Loss: 1.2191, Accuracy: 0.385\n",
      "[Epoch 92/100] -> Validation Loss: 1.0666, Accuracy: 0.496\n",
      "[Epoch 93/100] -> Train Loss: 1.2191, Accuracy: 0.386\n",
      "[Epoch 93/100] -> Validation Loss: 1.0666, Accuracy: 0.496\n",
      "[Epoch 94/100] -> Train Loss: 1.2191, Accuracy: 0.386\n",
      "[Epoch 94/100] -> Validation Loss: 1.0666, Accuracy: 0.496\n",
      "[Epoch 95/100] -> Train Loss: 1.2190, Accuracy: 0.385\n",
      "[Epoch 95/100] -> Validation Loss: 1.0665, Accuracy: 0.496\n",
      "[Epoch 96/100] -> Train Loss: 1.2190, Accuracy: 0.385\n",
      "[Epoch 96/100] -> Validation Loss: 1.0665, Accuracy: 0.496\n",
      "[Epoch 97/100] -> Train Loss: 1.2190, Accuracy: 0.386\n",
      "[Epoch 97/100] -> Validation Loss: 1.0664, Accuracy: 0.496\n",
      "[Epoch 98/100] -> Train Loss: 1.2190, Accuracy: 0.386\n",
      "[Epoch 98/100] -> Validation Loss: 1.0663, Accuracy: 0.496\n",
      "[Epoch 99/100] -> Train Loss: 1.2190, Accuracy: 0.386\n",
      "[Epoch 99/100] -> Validation Loss: 1.0661, Accuracy: 0.496\n",
      "[Epoch 100/100] -> Train Loss: 1.2190, Accuracy: 0.385\n",
      "[Epoch 100/100] -> Validation Loss: 1.0660, Accuracy: 0.496\n",
      "Training time: 88.6406798362732\n"
     ]
    }
   ],
   "source": [
    "hist = np.zeros(args.num_epochs)\n",
    "start_time = time.time()\n",
    "lstm = []\n",
    "for t in range(args.num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_train_pred = model(x_train)\n",
    "    loss = criterion(y_train_pred, y_train_lstm)\n",
    "    hist[t] = loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pred = torch.argmax(y_train_pred.softmax(dim=1), dim=1)\n",
    "    correct = pred.eq(y_train_lstm)\n",
    "    print('[Epoch {}/{}] -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(t + 1, args.num_epochs, loss.item(), correct.sum().item() / y_train_lstm.size(0)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        y_val_pred = model(x_val)\n",
    "        loss = criterion(y_val_pred, y_val_lstm)\n",
    "        pred = torch.argmax(y_val_pred.softmax(dim=1), dim=1)\n",
    "        correct = pred.eq(y_val_lstm)\n",
    "        print('[Epoch {}/{}] -> Validation Loss: {:.4f}, Accuracy: {:.3f}'.format(t + 1, args.num_epochs, loss.item(), correct.sum().item() / y_val_lstm.size(0)))\n",
    "    \n",
    "training_time = time.time()-start_time\n",
    "print(\"Training time: {}\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.475\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_test_pred = model(x_test)\n",
    "    pred = torch.argmax(y_test_pred.softmax(dim=1), dim=1)\n",
    "    correct = pred.eq(y_test_lstm)\n",
    "    print('Test Accuracy: {:.3f}'.format(correct.sum().item() / y_test_lstm.size(0)))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
