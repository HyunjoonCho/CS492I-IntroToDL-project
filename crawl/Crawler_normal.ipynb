{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29055eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "import FinanceDataReader as fdr\n",
    "from requests.adapters import HTTPAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935705cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStockData(symbol, startDate, endDate):\n",
    "    df_stock = fdr.DataReader(symbol, startDate.isoformat(), endDate.isoformat())\n",
    "    df_stock = df_stock[['Close']]\n",
    "    df_stock['Fluctuation'] = df_stock['Close'].div(df_stock['Close'].shift(1)).apply(lambda x : (x - 1) * 100)\n",
    "    return df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4674d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateTitles(companyName, url):\n",
    "    resp = requests.get(url)\n",
    "    titles = []\n",
    "\n",
    "    for item in bs(resp.text, 'xml').find_all('item'):\n",
    "        title = item.title.string\n",
    "        source = item.source.string # 언론사\n",
    "        if(companyName in title):\n",
    "            titles.append(title[:title.find(source) - 3])\n",
    "\n",
    "    return ' '.join(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67869ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyFluctuation(fluctuation):\n",
    "    if fluctuation < -2.5:\n",
    "        return 0\n",
    "    elif fluctuation < 0:\n",
    "        return 1\n",
    "    elif fluctuation < 2.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f07a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(companyName, startDate, endDate, isKor=True): \n",
    "    if isKor:\n",
    "        country = ('ko', 'KR')\n",
    "        symbol = str(df_kospi.loc[df_kospi['Name'] == companyName]['Symbol'].values[0])\n",
    "        print(f'Start crawling for {companyName} in Google News Korea')\n",
    "    else:\n",
    "        country = ('en', 'US')\n",
    "        symbol = df_snp.loc[df_snp['Name'] == companyName]['Symbol'].values[0]\n",
    "        print(f'Start crawling for {companyName} in Google News US')\n",
    "\n",
    "    df_stock = loadStockData(symbol, startDate - datetime.timedelta(days=1), endDate)\n",
    "    # df_stock.to_csv(f'./stock/{country[1]}/{companyName}_{startDate.isoformat()}_{endDate.isoformat()}.csv')\n",
    "    print(f'Loaded {companyName} price info, from {startDate.isoformat()} to {endDate.isoformat()}!')\n",
    "\n",
    "    dateList = df_stock.index.map(lambda x: datetime.datetime.strftime(x, '%Y-%m-%d')).values\n",
    "    fluctuationList = df_stock.loc[:, 'Fluctuation'].values\n",
    "\n",
    "    idx = 1\n",
    "    while idx < len(dateList):\n",
    "        url = f'https://news.google.com/rss/search?q={companyName}+after:{dateList[idx - 1]}+before:{dateList[idx]}& \\\n",
    "                hl={country[0]}&gl={country[1]}&ceid={country[1]}:{country[0]}'\n",
    "        aggTitle = aggregateTitles(companyName, url)\n",
    "        if aggTitle:\n",
    "            with open(f'./exp_my_3/{classifyFluctuation(fluctuationList[idx])}/{companyName}_{dateList[idx]}.txt', \n",
    "                        'w', encoding='UTF-8') as file:\n",
    "                file.write(aggTitle)\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start crawling for 삼성전자 in Google News Korea\n",
      "Loaded 삼성전자 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for SK하이닉스 in Google News Korea\n",
      "Loaded SK하이닉스 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for NAVER in Google News Korea\n",
      "Loaded NAVER price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 삼성바이오로직스 in Google News Korea\n",
      "Loaded 삼성바이오로직스 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 카카오 in Google News Korea\n",
      "Loaded 카카오 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for LG화학 in Google News Korea\n",
      "Loaded LG화학 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 삼성SDI in Google News Korea\n",
      "Loaded 삼성SDI price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 현대차 in Google News Korea\n",
      "Loaded 현대차 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 기아 in Google News Korea\n",
      "Loaded 기아 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 셀트리온 in Google News Korea\n",
      "Loaded 셀트리온 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 카카오뱅크 in Google News Korea\n",
      "Loaded 카카오뱅크 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 크래프톤 in Google News Korea\n",
      "Loaded 크래프톤 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for POSCO in Google News Korea\n",
      "Loaded POSCO price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for KB금융 in Google News Korea\n",
      "Loaded KB금융 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 현대모비스 in Google News Korea\n",
      "Loaded 현대모비스 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 카카오페이 in Google News Korea\n",
      "Loaded 카카오페이 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 삼성물산 in Google News Korea\n",
      "Loaded 삼성물산 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for SK이노베이션 in Google News Korea\n",
      "Loaded SK이노베이션 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for LG전자 in Google News Korea\n",
      "Loaded LG전자 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 신한지주 in Google News Korea\n",
      "Loaded 신한지주 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for LG생활건강 in Google News Korea\n",
      "Loaded LG생활건강 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for SK바이오사이언스 in Google News Korea\n",
      "Loaded SK바이오사이언스 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 하이브 in Google News Korea\n",
      "Loaded 하이브 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 엔씨소프트 in Google News Korea\n",
      "Loaded 엔씨소프트 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 한국전력 in Google News Korea\n",
      "Loaded 한국전력 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 삼성생명 in Google News Korea\n",
      "Loaded 삼성생명 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 두산중공업 in Google News Korea\n",
      "Loaded 두산중공업 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 하나금융지주 in Google News Korea\n",
      "Loaded 하나금융지주 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for HMM in Google News Korea\n",
      "Loaded HMM price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 삼성전기 in Google News Korea\n",
      "Loaded 삼성전기 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 삼성에스디에스 in Google News Korea\n",
      "Loaded 삼성에스디에스 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for SK아이이테크놀로지 in Google News Korea\n",
      "Loaded SK아이이테크놀로지 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for KT&G in Google News Korea\n",
      "Loaded KT&G price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 넷마블 in Google News Korea\n",
      "Loaded 넷마블 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 포스코케미칼 in Google News Korea\n",
      "Loaded 포스코케미칼 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 아모레퍼시픽 in Google News Korea\n",
      "Loaded 아모레퍼시픽 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 삼성화재 in Google News Korea\n",
      "Loaded 삼성화재 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 대한항공 in Google News Korea\n",
      "Loaded 대한항공 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for S-Oil in Google News Korea\n",
      "Loaded S-Oil price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 우리금융지주 in Google News Korea\n",
      "Loaded 우리금융지주 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 현대중공업 in Google News Korea\n",
      "Loaded 현대중공업 price info, from 2018-01-01 to 2018-12-31!\n",
      "Start crawling for 고려아연 in Google News Korea\n",
      "Loaded 고려아연 price info, from 2018-01-01 to 2018-12-31!\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    df_kospi = fdr.StockListing('KOSPI')\n",
    "    df_snp = fdr.StockListing('S&P500')\n",
    "    # May replace w/ fixed dictionary\n",
    "\n",
    "    startDate = datetime.date(2018, 1, 1) # inclusive\n",
    "    endDate = datetime.date(2018, 12, 31) # inclusive\n",
    "    companyListK = ['삼성전자', 'SK하이닉스', 'NAVER', '삼성바이오로직스', '카카오', 'LG화학', '삼성SDI', \n",
    "                    '현대차', '기아', '셀트리온', '카카오뱅크', '크래프톤', 'POSCO', 'KB금융', '현대모비스', \n",
    "                    '카카오페이', '삼성물산', 'SK이노베이션', 'LG전자', '신한지주', 'LG생활건강', 'SK바이오사이언스', \n",
    "                    '하이브', '엔씨소프트', '한국전력', '삼성생명', '두산중공업', '하나금융지주', 'HMM', '삼성전기', \n",
    "                    '삼성에스디에스', 'SK아이이테크놀로지', 'KT&G', '넷마블', '포스코케미칼', '아모레퍼시픽', '삼성화재', \n",
    "                    '대한항공', 'S-Oil', '우리금융지주', '현대중공업', '고려아연', '기업은행', 'KT', 'SK바이오팜', 'LG디스플레이', '한온시스템']\n",
    "    # 우리금융지주 수집 중 \"Remote end closed connection without\" urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
    "    # KOSPI 시총 상위 50개 종목, 지주회사 제외\n",
    "\n",
    "    for companyName in companyListK:\n",
    "        crawl(companyName, startDate, endDate)\n",
    "\n",
    "    # companyListUS = ['Apple', 'IBM', 'Delta Air Lines']\n",
    "    # for companyName in companyListUS:\n",
    "    #     crawl(companyName, startDate, endDate, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c7b083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
