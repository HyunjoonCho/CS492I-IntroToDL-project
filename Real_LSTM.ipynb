{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b29af52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 17:32:20.651446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-03 17:32:20.651468: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02051b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'NanumGothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb32ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb783c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyModel(companyName, predictDate):\n",
    "    symbol = str(df_kospi.loc[df_kospi['Name'] == companyName]['Symbol'].values[0])\n",
    "    companytable = fdr.DataReader(symbol)\n",
    "    companytable['Year'] = companytable.index.year\n",
    "    companytable['Month'] = companytable.index.month\n",
    "    companytable['Day'] = companytable.index.day\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scale_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    scaled = scaler.fit_transform(companytable[scale_cols])\n",
    "    df = pd.DataFrame(scaled, columns=scale_cols)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.4, random_state=0, shuffle=False)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=0, shuffle=False)\n",
    "    \n",
    "    WINDOW_SIZE=20\n",
    "    BATCH_SIZE=32\n",
    "    \n",
    "    train_data = windowed_dataset(y_train, WINDOW_SIZE, BATCH_SIZE, True)\n",
    "    validate_data = windowed_dataset(y_val, WINDOW_SIZE, BATCH_SIZE, True)\n",
    "    test_data = windowed_dataset(y_test, WINDOW_SIZE, BATCH_SIZE, False)\n",
    "    \n",
    "    model = Sequential([\n",
    "        # 1차원 feature map 생성\n",
    "        Conv1D(filters=32, kernel_size=5,\n",
    "               padding=\"causal\",\n",
    "               activation=\"relu\",\n",
    "               input_shape=[WINDOW_SIZE, 1]),\n",
    "        # LSTM\n",
    "        LSTM(16, activation='tanh'),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(1),\n",
    "    ])\n",
    "    \n",
    "    loss = Huber()\n",
    "    optimizer = Adam(0.0005)\n",
    "    model.compile(loss=Huber(), optimizer=optimizer, metrics=['mse'])\n",
    "    \n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    filename = os.path.join('tmp', 'ckeckpointer.ckpt')\n",
    "    checkpoint = ModelCheckpoint(filename, \n",
    "                                 save_weights_only=True, \n",
    "                                 save_best_only=True, \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1)\n",
    "    \n",
    "    history = model.fit(train_data, \n",
    "                        validation_data=(validate_data), \n",
    "                        epochs=50, \n",
    "                        callbacks=[checkpoint, earlystopping])\n",
    "    \n",
    "    model.load_weights(filename)\n",
    "    \n",
    "    #주어진 데이터 적용\n",
    "    forpredict = fdr.DataReader(symbol, predictDate - datetime.timedelta(days=40), predictDate- datetime.timedelta(days=1))\n",
    "    forpredict = forpredict[-20:]\n",
    "    scaler = MinMaxScaler()\n",
    "    scale_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    scaled = scaler.fit_transform(forpredict[scale_cols])\n",
    "    df = pd.DataFrame(scaled, columns=scale_cols)\n",
    "    my_test = df['Close']\n",
    "    my_test.loc['20'] = 0\n",
    "    my_test_data = windowed_dataset(my_test, WINDOW_SIZE, BATCH_SIZE, False)\n",
    "    my_pred = model.predict(my_test_data)\n",
    "    \n",
    "    myzeros = np.zeros((my_pred.shape[0],5))\n",
    "    newpred = my_pred + myzeros\n",
    "    price_pred = scaler.inverse_transform(newpred)\n",
    "    price_pred = price_pred[:,3:4]\n",
    "    \n",
    "    return price_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d696ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 17:32:39.444863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-03 17:32:39.445311: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-03 17:32:39.445386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-03 17:32:39.445449: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-03 17:32:39.447244: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-03 17:32:39.447308: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-03 17:32:39.447432: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-03 17:32:39.447703: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "    111/Unknown - 2s 5ms/step - loss: 5.1778e-05 - mse: 1.0356e-04\n",
      "Epoch 00001: val_loss improved from inf to 0.00142, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 5.1494e-05 - mse: 1.0299e-04 - val_loss: 0.0014 - val_mse: 0.0028\n",
      "Epoch 2/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 2.1578e-05 - mse: 4.3156e-05\n",
      "Epoch 00002: val_loss did not improve from 0.00142\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 2.2162e-05 - mse: 4.4323e-05 - val_loss: 0.0017 - val_mse: 0.0033\n",
      "Epoch 3/50\n",
      "101/112 [==========================>...] - ETA: 0s - loss: 1.9106e-05 - mse: 3.8212e-05\n",
      "Epoch 00003: val_loss did not improve from 0.00142\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 2.0454e-05 - mse: 4.0909e-05 - val_loss: 0.0015 - val_mse: 0.0031\n",
      "Epoch 4/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.9961e-05 - mse: 3.9923e-05\n",
      "Epoch 00004: val_loss improved from 0.00142 to 0.00103, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 2.0656e-05 - mse: 4.1312e-05 - val_loss: 0.0010 - val_mse: 0.0021\n",
      "Epoch 5/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.7921e-05 - mse: 3.5842e-05\n",
      "Epoch 00005: val_loss did not improve from 0.00103\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.9390e-05 - mse: 3.8780e-05 - val_loss: 0.0011 - val_mse: 0.0023\n",
      "Epoch 6/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.6711e-05 - mse: 3.3421e-05\n",
      "Epoch 00006: val_loss did not improve from 0.00103\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.7668e-05 - mse: 3.5336e-05 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 7/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.5949e-05 - mse: 3.1898e-05\n",
      "Epoch 00007: val_loss improved from 0.00103 to 0.00088, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.7178e-05 - mse: 3.4355e-05 - val_loss: 8.8437e-04 - val_mse: 0.0018\n",
      "Epoch 8/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.5796e-05 - mse: 3.1591e-05\n",
      "Epoch 00008: val_loss did not improve from 0.00088\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.6297e-05 - mse: 3.2595e-05 - val_loss: 9.5195e-04 - val_mse: 0.0019\n",
      "Epoch 9/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.4240e-05 - mse: 2.8480e-05\n",
      "Epoch 00009: val_loss improved from 0.00088 to 0.00073, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.6572e-05 - mse: 3.3144e-05 - val_loss: 7.2505e-04 - val_mse: 0.0015\n",
      "Epoch 10/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.4839e-05 - mse: 2.9679e-05\n",
      "Epoch 00010: val_loss improved from 0.00073 to 0.00070, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.6170e-05 - mse: 3.2340e-05 - val_loss: 7.0204e-04 - val_mse: 0.0014\n",
      "Epoch 11/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.3425e-05 - mse: 2.6849e-05\n",
      "Epoch 00011: val_loss did not improve from 0.00070\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.4516e-05 - mse: 2.9031e-05 - val_loss: 8.8105e-04 - val_mse: 0.0018\n",
      "Epoch 12/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.2181e-05 - mse: 2.4361e-05\n",
      "Epoch 00012: val_loss did not improve from 0.00070\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.3206e-05 - mse: 2.6412e-05 - val_loss: 9.3227e-04 - val_mse: 0.0019\n",
      "Epoch 13/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.2827e-05 - mse: 2.5654e-05\n",
      "Epoch 00013: val_loss did not improve from 0.00070\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.3945e-05 - mse: 2.7890e-05 - val_loss: 8.1405e-04 - val_mse: 0.0016\n",
      "Epoch 14/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.2742e-05 - mse: 2.5484e-05\n",
      "Epoch 00014: val_loss improved from 0.00070 to 0.00060, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.3699e-05 - mse: 2.7399e-05 - val_loss: 6.0164e-04 - val_mse: 0.0012\n",
      "Epoch 15/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.1727e-05 - mse: 2.3454e-05\n",
      "Epoch 00015: val_loss improved from 0.00060 to 0.00057, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.2342e-05 - mse: 2.4684e-05 - val_loss: 5.7000e-04 - val_mse: 0.0011\n",
      "Epoch 16/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.1735e-05 - mse: 2.3470e-05\n",
      "Epoch 00016: val_loss did not improve from 0.00057\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.2492e-05 - mse: 2.4983e-05 - val_loss: 7.0594e-04 - val_mse: 0.0014\n",
      "Epoch 17/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.0952e-05 - mse: 2.1904e-05\n",
      "Epoch 00017: val_loss did not improve from 0.00057\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.2083e-05 - mse: 2.4166e-05 - val_loss: 6.0253e-04 - val_mse: 0.0012\n",
      "Epoch 18/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.0658e-05 - mse: 2.1316e-05\n",
      "Epoch 00018: val_loss did not improve from 0.00057\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1308e-05 - mse: 2.2615e-05 - val_loss: 8.1990e-04 - val_mse: 0.0016\n",
      "Epoch 19/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.0757e-05 - mse: 2.1515e-05\n",
      "Epoch 00019: val_loss did not improve from 0.00057\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1318e-05 - mse: 2.2636e-05 - val_loss: 5.9767e-04 - val_mse: 0.0012\n",
      "Epoch 20/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 9.8993e-06 - mse: 1.9799e-05\n",
      "Epoch 00020: val_loss did not improve from 0.00057\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.0711e-05 - mse: 2.1423e-05 - val_loss: 7.2636e-04 - val_mse: 0.0015\n",
      "Epoch 21/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.0151e-05 - mse: 2.0302e-05\n",
      "Epoch 00021: val_loss did not improve from 0.00057\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.0820e-05 - mse: 2.1640e-05 - val_loss: 6.7336e-04 - val_mse: 0.0013\n",
      "Epoch 22/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 9.9470e-06 - mse: 1.9894e-05\n",
      "Epoch 00022: val_loss improved from 0.00057 to 0.00044, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.0550e-05 - mse: 2.1100e-05 - val_loss: 4.4354e-04 - val_mse: 8.8707e-04\n",
      "Epoch 23/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.0072e-05 - mse: 2.0143e-05\n",
      "Epoch 00023: val_loss did not improve from 0.00044\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1054e-05 - mse: 2.2108e-05 - val_loss: 4.8583e-04 - val_mse: 9.7165e-04\n",
      "Epoch 24/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.1072e-05 - mse: 2.2144e-05\n",
      "Epoch 00024: val_loss did not improve from 0.00044\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1701e-05 - mse: 2.3403e-05 - val_loss: 5.0506e-04 - val_mse: 0.0010\n",
      "Epoch 25/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 9.5558e-06 - mse: 1.9112e-05\n",
      "Epoch 00025: val_loss did not improve from 0.00044\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.0043e-05 - mse: 2.0085e-05 - val_loss: 4.5511e-04 - val_mse: 9.1022e-04\n",
      "Epoch 26/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 1.0623e-05 - mse: 2.1247e-05\n",
      "Epoch 00026: val_loss did not improve from 0.00044\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1082e-05 - mse: 2.2163e-05 - val_loss: 4.4700e-04 - val_mse: 8.9400e-04\n",
      "Epoch 27/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 9.2782e-06 - mse: 1.8556e-05\n",
      "Epoch 00027: val_loss did not improve from 0.00044\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 9.7422e-06 - mse: 1.9484e-05 - val_loss: 5.3333e-04 - val_mse: 0.0011\n",
      "Epoch 28/50\n",
      "101/112 [==========================>...] - ETA: 0s - loss: 8.9082e-06 - mse: 1.7816e-05\n",
      "Epoch 00028: val_loss did not improve from 0.00044\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 9.7781e-06 - mse: 1.9556e-05 - val_loss: 5.2424e-04 - val_mse: 0.0010\n",
      "Epoch 29/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 9.4646e-06 - mse: 1.8929e-05\n",
      "Epoch 00029: val_loss improved from 0.00044 to 0.00034, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.0047e-05 - mse: 2.0094e-05 - val_loss: 3.3558e-04 - val_mse: 6.7116e-04\n",
      "Epoch 30/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 9.0679e-06 - mse: 1.8136e-05\n",
      "Epoch 00030: val_loss did not improve from 0.00034\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 9.3759e-06 - mse: 1.8752e-05 - val_loss: 4.8631e-04 - val_mse: 9.7263e-04\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 9.1182e-06 - mse: 1.8236e-05\n",
      "Epoch 00031: val_loss did not improve from 0.00034\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 9.1182e-06 - mse: 1.8236e-05 - val_loss: 3.6586e-04 - val_mse: 7.3172e-04\n",
      "Epoch 32/50\n",
      "101/112 [==========================>...] - ETA: 0s - loss: 8.8412e-06 - mse: 1.7682e-05\n",
      "Epoch 00032: val_loss did not improve from 0.00034\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 9.3996e-06 - mse: 1.8799e-05 - val_loss: 4.4857e-04 - val_mse: 8.9713e-04\n",
      "Epoch 33/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 9.2672e-06 - mse: 1.8534e-05\n",
      "Epoch 00033: val_loss did not improve from 0.00034\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.0257e-05 - mse: 2.0513e-05 - val_loss: 4.1135e-04 - val_mse: 8.2270e-04\n",
      "Epoch 34/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 9.7826e-06 - mse: 1.9565e-05\n",
      "Epoch 00034: val_loss improved from 0.00034 to 0.00029, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.0676e-05 - mse: 2.1351e-05 - val_loss: 2.8730e-04 - val_mse: 5.7460e-04\n",
      "Epoch 35/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 8.8203e-06 - mse: 1.7641e-05\n",
      "Epoch 00035: val_loss improved from 0.00029 to 0.00026, saving model to tmp/ckeckpointer.ckpt\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 8.9467e-06 - mse: 1.7893e-05 - val_loss: 2.5760e-04 - val_mse: 5.1520e-04\n",
      "Epoch 36/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 9.9940e-06 - mse: 1.9988e-05\n",
      "Epoch 00036: val_loss did not improve from 0.00026\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1286e-05 - mse: 2.2571e-05 - val_loss: 2.6657e-04 - val_mse: 5.3315e-04\n",
      "Epoch 37/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 8.6639e-06 - mse: 1.7328e-05\n",
      "Epoch 00037: val_loss did not improve from 0.00026\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 9.0286e-06 - mse: 1.8057e-05 - val_loss: 5.4998e-04 - val_mse: 0.0011\n",
      "Epoch 38/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 8.3791e-06 - mse: 1.6758e-05\n",
      "Epoch 00038: val_loss did not improve from 0.00026\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 8.8716e-06 - mse: 1.7743e-05 - val_loss: 4.8042e-04 - val_mse: 9.6084e-04\n",
      "Epoch 39/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 7.3283e-06 - mse: 1.4657e-05\n",
      "Epoch 00039: val_loss did not improve from 0.00026\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 8.4401e-06 - mse: 1.6880e-05 - val_loss: 6.3619e-04 - val_mse: 0.0013\n",
      "Epoch 40/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 7.5660e-06 - mse: 1.5132e-05\n",
      "Epoch 00040: val_loss did not improve from 0.00026\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 8.6302e-06 - mse: 1.7260e-05 - val_loss: 4.7097e-04 - val_mse: 9.4194e-04\n",
      "Epoch 41/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 7.7323e-06 - mse: 1.5465e-05\n",
      "Epoch 00041: val_loss did not improve from 0.00026\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 8.5511e-06 - mse: 1.7102e-05 - val_loss: 4.6967e-04 - val_mse: 9.3933e-04\n",
      "Epoch 42/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 8.6371e-06 - mse: 1.7274e-05\n",
      "Epoch 00042: val_loss did not improve from 0.00026\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 9.0621e-06 - mse: 1.8124e-05 - val_loss: 6.0632e-04 - val_mse: 0.0012\n",
      "Epoch 43/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 8.7310e-06 - mse: 1.7462e-05\n",
      "Epoch 00043: val_loss did not improve from 0.00026\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 8.8748e-06 - mse: 1.7750e-05 - val_loss: 7.2801e-04 - val_mse: 0.0015\n",
      "Epoch 44/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 7.6348e-06 - mse: 1.5270e-05\n",
      "Epoch 00044: val_loss did not improve from 0.00026\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 8.2515e-06 - mse: 1.6503e-05 - val_loss: 4.6949e-04 - val_mse: 9.3898e-04\n",
      "Epoch 45/50\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 8.0015e-06 - mse: 1.6003e-05\n",
      "Epoch 00045: val_loss did not improve from 0.00026\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 8.7535e-06 - mse: 1.7507e-05 - val_loss: 4.0538e-04 - val_mse: 8.1076e-04\n"
     ]
    }
   ],
   "source": [
    "df_kospi = fdr.StockListing('KOSPI')\n",
    "\n",
    "predict_Date = datetime.date(2021 , 12, 3) \n",
    "#주가 예측을 원하는 날짜\n",
    "#현재는 하루 이후만 가능함, 과거 날짜는 모두 괜찮음(아직 안나온 기준 하루)\n",
    "predict_Company = '호텔신라' \n",
    "#주가 예측을 원하는 기업\n",
    "\n",
    "predicted_price = applyModel(predict_Company, predict_Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8014190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 가격은 72997.45427668095 원\n"
     ]
    }
   ],
   "source": [
    "print(\"예측 가격은\", predicted_price[0][0],\"원\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
